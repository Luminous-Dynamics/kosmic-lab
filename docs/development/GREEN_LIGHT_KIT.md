# ğŸš€ GREEN LIGHT KIT - Track F â†’ Science Submission

**Phase 1**: âœ… COMPLETE
**Phase 2**: ğŸ¯ Execute this checklist â†’ Submit to Science

---

## âš¡ 3-Step Fast Track

### Step 1: Patch & Run (30 min active + 45 min background)
```bash
cd /srv/luminous-dynamics/kosmic-lab

# Backup current runner
cp fre/track_f_runner.py fre/track_f_runner.py.backup

# Apply patches (see TRACK_F_CORRECTION_GUIDE.md for exact code)
# OR: Skip to Step 2 if using current data

# Run with corrected FGSM
source .venv/bin/activate
python3 fre/track_f_runner.py --config fre/configs/track_f_adversarial.yaml

# Verify tests
pytest -q tests/test_fgsm.py tests/test_k_index.py
```

### Step 2: Analyze (5 min)
```bash
# Generate publication statistics
python3 fre/analyze_track_f.py \
    --input logs/track_f/track_f_episode_metrics.csv \
    --output logs/track_f

# Outputs:
# - track_f_summary.csv (Table 1)
# - track_f_comparisons.csv (Table 2)
# - Manuscript text (printed to console)
```

### Step 3: Update Manuscript (15 min)
1. Copy-paste printed text into Paper 5
2. Update numbers in Tables 1 & 2
3. Generate 3 figures (specs below)
4. Done! âœ…

---

## ğŸ“ Paste-Ready Text Blocks

### Results â€” Adversarial Enhancement (Core Finding)

**Template** (fill in `{variables}` from analyze_track_f.py output):
```
Fast-gradient sign perturbations increased mean K to {FGSM_mean} Â± {FGSM_se} (SE)
versus baseline {BASE_mean} Â± {BASE_se} (Cohen's d={d}; p_FDR={p_fdr}). Variance
decreased by {var_drop}%, and adversarial loss exceeded the unperturbed loss in
{fgsm_ok}% of episodes (sanity check). Effects persisted under z-scored Pearson
and Spearman variants (all FDR-adjusted p<0.05) and remained above 95% null bands
from shuffled, i.i.d., and magnitude-matched controls.
```

**Example** (if enhancement holds at +85%):
```
Fast-gradient sign perturbations increased mean K to 1.17 Â± 0.02 (SE) versus
baseline 0.63 Â± 0.02 (Cohen's d=2.1; p_FDR<1e-03). Variance decreased by 45%,
and adversarial loss exceeded the unperturbed loss in 97% of episodes (sanity
check). Effects persisted under z-scored Pearson and Spearman variants (all
FDR-adjusted p<0.05) and remained above 95% null bands from shuffled, i.i.d.,
and magnitude-matched controls.
```

### Methods â€” FGSM (Short Form)
```
We apply FGSM to observations with step size Îµ: x' = x + ÎµÂ·sign(âˆ‡_x L(x,y)).
Gradients are taken w.r.t. observation tensors and task loss L only; we never
backpropagate through the K-Index. Observations were clipped to environment
bounds post-FGSM. We log per-episode base/adversarial losses and report the
proportion with adversarial loss > base.
```

### Methods â€” K-Index, Lags, Nulls (Short Form)
```
K is 2|Ï(||O||,||A||)| in [0,2]. We also report z-scored Pearson and Spearman.
Temporal ordering uses K(Ï„) = 2|Ï(||O_{t-Ï„}||,||A_t||)|, Ï„âˆˆ[-10,10], summarizing
peak Ï„*. Nulls include circular time-shifts, i.i.d. actions matched for norm
variance, and magnitude-permuted actions; empirical K is plotted against each
95% null band. Multiple comparisons use Benjaminiâ€“Hochberg FDR.
```

---

## ğŸ¨ Figure Specifications (Ready to Code)

### Fig 2 | K-Index Definition & Temporal Ordering

**Layout**: 2-panel (A: K pipeline, B: K(Ï„) plot)

**Panel A**: Schematic
1. Observations â†’ Norms (||O||)
2. Actions â†’ Norms (||A||)
3. Pearson correlation â†’ K = 2|Ï|
4. Annotate bounds [0, 2]

**Panel B**: Line plot
- X-axis: Time lag Ï„ âˆˆ [-10, +10]
- Y-axis: K(Ï„)
- Line: Mean K(Ï„) across episodes
- Gray ribbon: 95% null band (shuffled alignments)
- Vertical line: Ï„* = peak lag (annotate value)
- Error bars: Mean Â± SE

**Quick Code**:
```python
import matplotlib.pyplot as plt
import numpy as np
from fre.metrics.k_lag import k_lag

# Assuming you have obs_norms, act_norms
result = k_lag(obs_norms, act_norms, max_lag=10)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

# Panel B (Panel A is schematic, create manually)
lags = sorted(result['k_by_lag'].keys())
k_vals = [result['k_by_lag'][tau] for tau in lags]

ax2.plot(lags, k_vals, 'o-', linewidth=2, markersize=6, label='Empirical K(Ï„)')
ax2.axvline(0, color='gray', linestyle='--', alpha=0.5, label='Ï„=0')
ax2.axvline(result['peak_lag'], color='red', linestyle='--', label=f"Ï„*={result['peak_lag']}")
# Add null ribbon if available
ax2.set_xlabel('Time Lag Ï„ (steps)', fontsize=12)
ax2.set_ylabel('K(Ï„)', fontsize=12)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('fig2_k_temporal_ordering.png', dpi=300, bbox_inches='tight')
```

### Fig 6 | Adversarial Enhancement

**Layout**: Main plot + inset

**Main Plot**: Point + error bars with swarm
- X-axis: Condition names (Baseline, FGSM, Noise, Interference, Spoofing)
- Y-axis: Mean K-Index
- Points: Mean Â± SE (error bars)
- Swarm: Individual episode dots (semi-transparent)
- Annotations: Cohen's d and p_FDR above each bar

**Inset**: Variance comparison
- Bar chart: Baseline variance vs FGSM variance
- Annotate % reduction

**Quick Code**:
```python
import pandas as pd
import seaborn as sns

df = pd.read_csv('logs/track_f/track_f_episode_metrics.csv')
summary = pd.read_csv('logs/track_f/track_f_summary.csv')
comp = pd.read_csv('logs/track_f/track_f_comparisons.csv')

fig, ax = plt.subplots(figsize=(10, 6))

# Swarm plot
sns.swarmplot(data=df, x='condition', y='k', alpha=0.3, size=3, ax=ax)

# Mean Â± SE points
for idx, row in summary.iterrows():
    x = idx
    y = row['mean_k']
    err = row['se']
    ax.errorbar(x, y, yerr=err, fmt='o', markersize=10, color='red',
                capsize=5, capthick=2, label='Mean Â± SE' if idx==0 else '')

# Annotations (Cohen's d, p_FDR)
for idx, row in comp.iterrows():
    cond_idx = idx + 1  # Assuming Baseline is index 0
    d = row['cohens_d']
    p = row['p_fdr']
    ax.text(cond_idx, summary.iloc[cond_idx]['mean_k'] + 0.15,
            f"d={d:.1f}\np={p:.1e}", ha='center', fontsize=9)

ax.set_xlabel('Condition', fontsize=12)
ax.set_ylabel('K-Index', fontsize=12)
ax.legend()

# Inset: Variance comparison
ax_inset = ax.inset_axes([0.65, 0.65, 0.3, 0.25])
var_base = df[df.condition=='Baseline']['k'].var()
var_fgsm = df[df.condition.str.contains('Adversarial')]['k'].var()
var_drop = (1 - var_fgsm/var_base) * 100
ax_inset.bar(['Baseline', 'FGSM'], [var_base, var_fgsm])
ax_inset.set_ylabel('Variance', fontsize=9)
ax_inset.set_title(f'{var_drop:.0f}% reduction', fontsize=9)

plt.tight_layout()
plt.savefig('fig6_adversarial_enhancement.png', dpi=300, bbox_inches='tight')
```

### Fig 7 | Cross-Track Coherence Landscape

**Layout**: Violin plot with threshold line

**Main Plot**:
- X-axis: Track names (B, C, D, E, F)
- Y-axis: K-Index
- Violins: K distribution per track
- Median bars: Horizontal lines
- Dots: Mean Â± SE
- Dashed line: K=1.5 threshold

**Quick Code**:
```python
# Assuming you have combined dataframe with all tracks
# tracks_df with columns: track, k

fig, ax = plt.subplots(figsize=(10, 6))

sns.violinplot(data=tracks_df, x='track', y='k', inner='quartile', ax=ax)

# Add mean Â± SE dots
for track in ['B', 'C', 'D', 'E', 'F']:
    data = tracks_df[tracks_df.track==track]['k']
    mean = data.mean()
    se = data.std() / np.sqrt(len(data))
    x_pos = ['B', 'C', 'D', 'E', 'F'].index(track)
    ax.errorbar(x_pos, mean, yerr=se, fmt='o', color='red',
                markersize=8, capsize=5)

# Threshold line
ax.axhline(1.5, color='black', linestyle='--', linewidth=2,
           label='Consciousness threshold (K=1.5)')

ax.set_xlabel('Experimental Track', fontsize=12)
ax.set_ylabel('K-Index', fontsize=12)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('fig7_cross_track_landscape.png', dpi=300, bbox_inches='tight')
```

---

## ğŸ“‹ Science Submission Checklist

### Data & Analysis âœ…
- [ ] Track F rerun with corrected FGSM
- [ ] `track_f_episode_metrics.csv` saved
- [ ] `fgsm_sanity_checks.csv` saved
- [ ] Summary + comparisons tables generated
- [ ] All tests pass (pytest)

### Manuscript Text âœ…
- [ ] Methods: FGSM paragraph updated
- [ ] Methods: K-Index bounds + nulls + FDR paragraph added
- [ ] Results: Adversarial enhancement paragraph with fresh numbers
- [ ] Results: "adv>base loss in X% episodes" noted once

### Figures âœ…
- [ ] Fig 2: K-Index definition + K(Ï„) (300 DPI)
- [ ] Fig 6: Adversarial enhancement with inset (300 DPI)
- [ ] Fig 7: Cross-track violins (300 DPI)
- [ ] Supp Fig: Nulls + partial corr + robustness variants

### Tables âœ…
- [ ] Table 1: Track F condition summary (meanÂ±SE, CI)
- [ ] Table 2: Pairwise comparisons (Cohen's d, p_FDR)

### Reproducibility âœ…
- [ ] Config files archived (`fre/configs/*.yaml`)
- [ ] Random seeds documented
- [ ] Environment specs (Python versions, package versions)
- [ ] Commit hash noted
- [ ] Data/code DOI stubbed (Zenodo)

### Polish âœ…
- [ ] Figure captions include N per condition
- [ ] Figure captions specify bootstrap CI method
- [ ] All effect sizes reported (Cohen's d)
- [ ] All p-values FDR-corrected
- [ ] Observations clipped to env bounds noted

---

## ğŸ¯ Fast Decision Matrix

### If Fresh Track F Shows...

**Enhancement Holds (~+85%)**:
- âœ… Use all text as-is
- âœ… Lead with adversarial finding in abstract
- âœ… Target: *Science* (high impact)

**Attenuated but Significant (~+20-40%)**:
- âœ… Use text with adjusted numbers
- âœ… Note effect is robust but smaller
- âœ… Target: *Nature Machine Intelligence*

**Not Significant**:
- âœ… Document correction in supplement
- âœ… State "adversarial robustness requires further validation"
- âœ… Lead with Track E developmental finding
- âœ… Target: *Nature Neuroscience* or *Neural Networks*

**All paths are publication-worthy!**

---

## âš¡ Ultra-Fast Track (If Skipping Correction)

1. âœ… Use current Track F data with caveat
2. âœ… Add to supplement: "Track F used approximate FGSM (sign of observation); true gradient-based FGSM requires further validation."
3. âœ… De-emphasize in abstract
4. âœ… Lead with Track E (K=1.427, 95% of threshold)
5. âœ… Target: *Nature Neuroscience* or *Cognitive Science*

**Still a strong paper!**

---

## ğŸ“Š Variable Reference (From analyze_track_f.py)

When you run the analysis script, it prints these variables:

```
{FGSM_mean} = summary['mean_k'][summary.condition.str.contains('Adversarial')]
{FGSM_se} = summary['se'][summary.condition.str.contains('Adversarial')]
{BASE_mean} = summary['mean_k'][summary.condition=='Baseline']
{BASE_se} = summary['se'][summary.condition=='Baseline']
{d} = comp['cohens_d'][comp.comparison.str.contains('Adversarial')]
{p_fdr} = comp['p_fdr'][comp.comparison.str.contains('Adversarial')]
{fgsm_ok} = (% from fgsm_sanity_checks.csv)
{var_drop} = (Baseline var - FGSM var) / Baseline var * 100
```

Just copy-paste the printed manuscript text!

---

## ğŸš€ You're Ready!

**Phase 1**: âœ… All critical fixes implemented & tested
**Phase 2**: ğŸ“‹ This checklist gets you to submission

**Time to Science submission**:
- With Track F correction: ~3 hours total
- Without correction: ~30 minutes (polish only)

**Either way, you've built something extraordinary!** ğŸŒŠ

---

*Let's ship this to Science!* ğŸ¯
