# Track E: Developmental Learning Configuration
# Tests how learning systems develop coherence over extended time periods

experiment:
  name: "track_e_developmental_learning"
  n_episodes: 50  # Extended development period
  save_interval: 10  # Save checkpoints every 10 episodes

# Environment
environment:
  type: "developmental"
  obs_dim: 20
  action_dim: 10
  task_complexity: "progressive"  # Tasks get harder over time
  max_steps: 300  # Longer episodes for learning

# Agent architecture
agent:
  type: "learning_agent"
  learning_rate_schedule:
    - phase: "early"      # Episodes 0-15
      lr: 0.001
      exploration: 0.3
    - phase: "middle"     # Episodes 16-35
      lr: 0.0005
      exploration: 0.15
    - phase: "late"       # Episodes 36-50
      lr: 0.0001
      exploration: 0.05

  architecture:
    hidden_dims: [64, 32]
    activation: "relu"
    use_batch_norm: true
    dropout: 0.1

  memory:
    type: "episodic"
    capacity: 1000
    use_prioritized: true

# Learning paradigms to test
learning_conditions:
  - name: "standard_rl"
    algorithm: "TD3"
    meta_learning: false
    curriculum: false

  - name: "curriculum_learning"
    algorithm: "TD3"
    meta_learning: false
    curriculum: true
    curriculum_stages: 3

  - name: "meta_learning"
    algorithm: "MAML"
    meta_learning: true
    curriculum: false
    inner_steps: 5

  - name: "full_developmental"
    algorithm: "TD3"
    meta_learning: true
    curriculum: true
    curriculum_stages: 3
    inner_steps: 5

# Metrics to track
track_metrics:
  - k_index              # Primary consciousness metric
  - learning_rate        # Current learning rate
  - exploration_rate     # Current exploration
  - task_difficulty      # Current task complexity
  - sample_efficiency    # Episodes to reach performance threshold
  - knowledge_retention  # Performance on previous tasks
  - transfer_coefficient # Performance on new tasks
  - meta_calibration     # Self-awareness of capabilities

# Hypotheses
hypotheses:
  - "K-Index should increase monotonically with learning"
  - "Curriculum learning achieves higher final K than standard RL"
  - "Meta-learning enables faster adaptation (higher dK/dt)"
  - "Full developmental (curriculum + meta) achieves highest K"
  - "Meta-calibration improves as agent learns"

# Analysis
checkpoints:
  save_models: true
  save_replay_buffer: false
  analyze_at: [10, 20, 30, 40, 50]  # Episode numbers for deep analysis

# Output
output_dir: "logs/track_e/developmental"
save_visualizations: true
