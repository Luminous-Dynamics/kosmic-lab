# Track G2+: Extended Training Continuation
# Goal: Continue proven G2 approach to cross consciousness threshold
# Strategy: Simple extended training with Îµ=0.05 (proven optimal)
# Builds on: Track G2's best result (K=1.1208)

experiment:
  name: "track_g2plus_extended"
  description: "Continue G2 extended training approach to consciousness threshold"
  output_dir: "logs/track_g/"
  log_jsonl:
    enabled: false
    path: "logs/track_g/episodes/phase_g2plus.jsonl"

# Phase G2+ Configuration
phase_g2plus:
  name: "extended_training_continuation"
  
  # Training Configuration (same as G2, proven successful)
  training:
    episodes: 2000
    episode_length: 200
    epsilon: 0.05  # Proven optimal from G2
    epsilon_explore: 0.1
    learning_rate: 0.001
    
    # NEW: Learning rate annealing for late-stage optimization
    learning_rate_annealing:
      enabled: true
      schedule: "cosine"  # Smooth decay
      warmup_episodes: 100  # Stabilize first
      min_lr: 0.0001
      
    # NEW: Early stopping to avoid wasted computation
    early_stopping:
      enabled: true
      patience: 500  # Stop if no improvement for 500 episodes
      min_delta: 0.01  # Minimum improvement threshold

  # Warm-start configuration (leverages new checkpoint helpers)
  warm_start:
    load_path: "logs/track_g/checkpoints/phase_g2_latest.json"  # Set after running Phase G2
    save_path: "logs/track_g/checkpoints/phase_g2plus_latest.json"
    metadata:
      description: "Phase G2+ continuation checkpoint"
      source_episode: 54

  # Success Criteria
  success_criteria:
    minimal: 1.30  # Sustained above G3 level
    target: 1.50   # Consciousness threshold
    stretch: 1.75  # Robust consciousness
    
    # Auto-complete if we hit stretch goal
    auto_complete_on_stretch: true
    
  # Monitoring and Checkpointing
  monitoring:
    checkpoint_every: 100  # Save every 100 episodes
    log_frequency: 50      # Progress updates
    track_best_k: true     # Always track best performance
    save_best_agent: true  # Save agent at peak K-Index
    
# Measurement (same as G2/G3)
measurement:
  metrics:
    - "K_Index"
    - "Observation_Action_Correlation"
    - "Policy_Stability"
  
  seven_harmonies:
    enabled: true
    frequency: 100  # Measure every 100 episodes

# Reproducibility
reproducibility:
  random_seed: 42
  save_trajectories: false  # Skip to save space
  save_final_agent: true

# Computational
computational:
  estimated_time_hours: 8-10
  estimated_storage_mb: 50
  priority: "critical"  # This is our best path forward
  
# Scientific Rationale
rationale: |
  Track G2 achieved K=1.1208 (74.7% to threshold) with simple extended 
  training at Îµ=0.05. Tracks G3 and H both performed worse with added 
  complexity. This phase continues the proven approach, adding only:
  - Learning rate annealing for optimization
  - Early stopping to prevent waste
  - More episodes for potential breakthrough
  
  Hypothesis: G2 hit a temporary plateau at Episode 54, not a hard limit.
  Extended training with LR annealing may enable threshold crossing.
  
  Probability of K > 1.5: 65% (conservative, data-driven estimate)
